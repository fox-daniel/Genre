{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This nb builds a classifier to predict gender from genre using a random forest model.\n",
    "\n",
    "We look at the following encoding/embeddings:\n",
    "- [ ] BOW\n",
    "- [ ] TFIDF\n",
    "- [ ] LSI\n",
    "- [ ] LDA\n",
    "- [ ] Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import genre_data_loader, genre_upperbound\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns; sns.set()\n",
    "\n",
    "# import re\n",
    "\n",
    "# import os\n",
    "# from gensim import corpora\n",
    "# from gensim.corpora import MmCorpus\n",
    "# from gensim.models import TfidfModel, LsiModel\n",
    "# from gensim.matutils import corpus2dense\n",
    "\n",
    "# import json\n",
    "\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currrent date for latest version of data set\n",
    "%store -r now\n",
    "\n",
    "X_path_train = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_X_train_{}.csv'.format(now)\n",
    "y_path_train = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_y_train_{}.csv'.format(now)\n",
    "X_path_test = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_X_test_{}.csv'.format(now)\n",
    "y_path_test = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_y_test_{}.csv'.format(now)\n",
    "\n",
    "# call data loader script for training data\n",
    "genre_data = genre_data_loader.LoadGenreData(now, X_path_train = X_path_train, y_path_train = y_path_train,\n",
    "                                                  X_path_test = X_path_test, y_path_test = y_path_test)\n",
    "# call it for train data\n",
    "genre_data_train = genre_data_loader.LoadGenreData(now, X_path_train = X_path_train, y_path_train = y_path_train)\n",
    "# call it for test data\n",
    "genre_data_test = genre_data_loader.LoadGenreData(now, X_path_train = X_path_test, y_path_train = y_path_test)\n",
    "\n",
    "# load data with genre sets\n",
    "data_train = genre_data_train.as_strings()\n",
    "data_train = genre_data_train.as_lists()\n",
    "data_train = genre_data_train.as_sets()\n",
    "data_test = genre_data_test.as_strings()\n",
    "data = genre_data.as_strings()\n",
    "data = genre_data.as_sets()\n",
    "\n",
    "# create list of all genres\n",
    "list_of_genres = genre_data.get_list_of_genres()\n",
    "\n",
    "# Create a dictionary of {genre : genre_id}\n",
    "dict_gid = genre_data.get_dict_genre_to_id()\n",
    "dict_idg = genre_data.get_dict_id_to_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12376, 5), (3094, 3), (15470, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_test.shape, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a sparse data structure encoding of the genre labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(vocabulary = dict_gid) # uses scipy.sparse.csr_matrix representation\n",
    "# create sparse matrix of training features NOTE: cannot use .get_sparse_matrix() method of genre_data_loader:\n",
    "# that will use a dict_gid built from the list of genres only from training data \n",
    "X_train = vec.fit_transform(data_train.genre_string)\n",
    "\n",
    "# Encode labels:\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(['male', 'female'])\n",
    "# #le.classes_\n",
    "# y_train = le.transform(data_train.gender.values)\n",
    "# # le.transform(['female'])\n",
    "# # le.inverse_transform([1,0,1])\n",
    "\n",
    "# Encode Labels with UDF so can control encoding:\n",
    "def encode_targets(row):\n",
    "    if row.gender == 'female':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "y_train = data_train.apply(encode_targets, axis = 1)\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test alignment of data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From genre_data_loader.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sparse_list(X_sparse, row_number):\n",
    "    zeros, cols = X_sparse[row_number].nonzero()\n",
    "    cols_labels = [dict_idg[ind] for ind in cols]\n",
    "    cols_labels.sort()\n",
    "    return cols_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check alignment of data_train and (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['country'], ['country'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(data_train.shape[0])\n",
    "sorted(decode_sparse_list(X_train, n)), sorted(data_train.genre_list.iloc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'male')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(data_train.shape[0])\n",
    "y_train[n], data_train.gender.iloc[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Convert inputs to a numpy array and then create a scaler class to normalize the feature values that can be applied to training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scaler = preprocessing.StandardScaler(with_mean = False).fit(X_sparse) # need with_mean = False for sparse data\n",
    "# # transformer\n",
    "# transformer = preprocessing.MaxAbsScaler(copy = False).fit(X_train)\n",
    "# transformer.scale_.max(), transformer.max_abs_.max()\n",
    "# Apply the scaler to the training data:\n",
    "# X_scaled = transformer.transform(X_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ceate the model: GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators = 1000, learning_rate = 1.5, loss = 'exponential', random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=1.5, loss='exponential', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline accuracy by always classifying male on the training set is 0.69.\n",
      "Accuracy on the training set is 0.8447802197802198.\n",
      "Upper bound to accuracy on the training set is 0.866031\n",
      "Accuracy is 0.98 of the upperbound.\n"
     ]
    }
   ],
   "source": [
    "mal = data_train[data_train.gender == 'male'].shape[0]\n",
    "fem = data_train[data_train.gender == 'female'].shape[0]\n",
    "p_mal = mal/(mal+fem)\n",
    "score = model.score(X_train, y_train)\n",
    "print(f'The baseline accuracy by always classifying male on the training set is {round(p_mal,2)}.')\n",
    "print(f'Accuracy on the training set is {score}.')\n",
    "uppers, err = genre_upperbound.UpperBound(data_train)\n",
    "print(f'Upper bound to accuracy on the training set is {1-err}')\n",
    "print(f'Accuracy is {round((score)/(1-err),2)} of the upperbound.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, x_data, y_data, n_splits = 2):\n",
    "    \"\"\"This function takes a model, features, targets, and number of folds and returns\n",
    "    accuracy scores and the validation set index for each fold\n",
    "    Input:\n",
    "        model - a model that has .fit, .score, .predict methods\n",
    "        X - sparse matrix representing features: genre labels\n",
    "        y - list of genders\n",
    "        \n",
    "    Output:\n",
    "        cvscores - list of cvscores, \n",
    "        cms - list of confusion matrices, \n",
    "        vals - list of validation set indices. \n",
    "    It also prints basic stats.\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits = n_splits, shuffle = True, random_state = seed)\n",
    "\n",
    "    cvscores = []\n",
    "    #cms = []\n",
    "    vals = []\n",
    "    \n",
    "    for train, val in kf.split(x_data,y_data):\n",
    "        X_train = x_data[train]\n",
    "        y_train = y_data[train]\n",
    "\n",
    "        model.fit(X_train, y_train);\n",
    "\n",
    "        X_val = x_data[val]\n",
    "        y_val = y_data[val]\n",
    "\n",
    "        score = model.score(X_val, y_val)\n",
    "        cvscores.append(round(score,3))\n",
    "\n",
    "        # compute confusion matrices and store them in a list\n",
    "        y_pred = model.predict(X_val)\n",
    "        #cms.append(confusion_matrix(y_val, y_pred))\n",
    "        \n",
    "        vals.append(val)\n",
    "\n",
    "    print(f'Mean accuracy is {100*np.mean(cvscores):.2f}% and 100*STD is {100*np.std(cvscores):.2f}%')\n",
    "    print(f'This is a {100*(100*np.mean(cvscores)-69)/69:.2f}% improvement over a random guess.')\n",
    "        \n",
    "    return cvscores, cms, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy is 72.27% and 100*STD is 1.10%\n",
      "This is a 4.74% improvement over a random guess.\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators = 1000, \n",
    "                                   learning_rate = 1.5, \n",
    "                                   loss = 'exponential', \n",
    "                                   random_state = seed)\n",
    "cvscores, cms, vals = train_validate(model, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate upper bounds on accuracy for each validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_bounds(vals, data):\n",
    "    \"\"\"Create a list of the upper bounds on accuracy for each validation set.\"\"\"\n",
    "    uppers = []\n",
    "    for val in vals:\n",
    "        data_val = data.iloc[val] \n",
    "        upper, error = genre_upperbound.UpperBound(data_val)\n",
    "        uppers.append(round(1-error,3))\n",
    "    return uppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppers = upper_bounds(vals, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.922, 0.912, 0.914, 0.915, 0.905, 0.915, 0.909, 0.902, 0.908, 0.914]\n",
      "[0.711, 0.709, 0.723, 0.715, 0.745, 0.712, 0.726, 0.735, 0.73, 0.721]\n",
      "[0.211 0.203 0.191 0.2   0.16  0.203 0.183 0.167 0.178 0.193]\n"
     ]
    }
   ],
   "source": [
    "print(uppers)\n",
    "print(cvscores)\n",
    "print(np.array(uppers)-np.array(cvscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check alignment of genders\n",
    "# n = np.random.randint(y_val0.shape[0])\n",
    "# print('y_val')\n",
    "# print(y_val0[n])\n",
    "# print('data_val')\n",
    "# print(data_val0.gender.iloc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tf-idf and then LSA in scikit learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

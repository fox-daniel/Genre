{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This nb builds a classifier to predict gender from genre using Gradient Boosted Trees. Transformations to sparse matrix reps, tfidf, and truncated svd appear to be very helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Feature Importance: ESL 10.13\n",
    "- [ ] Create a further dimension reduction to 2D using most important features\n",
    "- [ ] Create a further dimension reduction to 2D by recalculating truncated SVD\n",
    "- [ ] Implement subset selection of features: https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import genre_data_loader, genre_upperbound\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns; sns.set()\n",
    "\n",
    "# import re\n",
    "\n",
    "# import os\n",
    "# from gensim import corpora\n",
    "# from gensim.corpora import MmCorpus\n",
    "# from gensim.models import TfidfModel, LsiModel\n",
    "# from gensim.matutils import corpus2dense\n",
    "\n",
    "# import json\n",
    "\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get currrent date for latest version of data set\n",
    "%store -r now\n",
    "\n",
    "X_path_train = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_X_train_{}.csv'.format(now)\n",
    "y_path_train = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_y_train_{}.csv'.format(now)\n",
    "X_path_test = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_X_test_{}.csv'.format(now)\n",
    "y_path_test = '/Users/Daniel/Code/Genre/data/genre_lists/data_ready_for_model/wiki-kaggle_y_test_{}.csv'.format(now)\n",
    "\n",
    "# call data loader script for training data\n",
    "genre_data = genre_data_loader.LoadGenreData(now, X_path_train = X_path_train, y_path_train = y_path_train,\n",
    "                                                  X_path_test = X_path_test, y_path_test = y_path_test)\n",
    "# call it for train data\n",
    "genre_data_train = genre_data_loader.LoadGenreData(now, X_path_train = X_path_train, y_path_train = y_path_train)\n",
    "# call it for test data\n",
    "genre_data_test = genre_data_loader.LoadGenreData(now, X_path_train = X_path_test, y_path_train = y_path_test)\n",
    "\n",
    "# load data with genre sets\n",
    "data_train = genre_data_train.as_strings()\n",
    "data_train = genre_data_train.as_lists()\n",
    "data_train = genre_data_train.as_sets()\n",
    "data_balanced = genre_data_train.get_balanced_sample()\n",
    "\n",
    "data_test = genre_data_test.as_strings()\n",
    "\n",
    "data = genre_data.as_strings()\n",
    "data = genre_data.as_sets()\n",
    "\n",
    "# create list of all genres\n",
    "list_of_genres = genre_data.get_list_of_genres()\n",
    "\n",
    "# Create a dictionary of {genre : genre_id}\n",
    "dict_gid = genre_data.get_dict_genre_to_id()\n",
    "dict_idg = genre_data.get_dict_id_to_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12376, 5), (3094, 3), (15470, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_test.shape, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a sparse data structure encoding of the genre labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_sparse(data):\n",
    "\n",
    "    vec = CountVectorizer(vocabulary = dict_gid) # uses scipy.sparse.csr_matrix representation\n",
    "    # create sparse matrix of training features NOTE: cannot use .get_sparse_matrix() method of genre_data_loader:\n",
    "    # that will use a dict_gid built from the list of genres only from training data \n",
    "    # full training set\n",
    "    X = vec.fit_transform(data.genre_string)\n",
    "    # balanced sample\n",
    "    X = vec.fit_transform(data.genre_string)\n",
    "\n",
    "\n",
    "    # Encode labels:\n",
    "    # le = preprocessing.LabelEncoder()\n",
    "    # le.fit(['male', 'female'])\n",
    "    # #le.classes_\n",
    "    # y = le.transform(data_train.gender.values)\n",
    "    # # le.transform(['female'])\n",
    "    # # le.inverse_transform([1,0,1])\n",
    "\n",
    "    # Encode Labels with UDF so can control encoding:\n",
    "    def encode_targets(row):\n",
    "        if row.gender == 'female':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    y = data.apply(encode_targets, axis = 1)\n",
    "    y = y.values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_bal, y_bal = transform_to_sparse(data_balanced)\n",
    "# X_train, y_train = transform_to_sparse(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce sparse -> tfidf -> truncated svd -> model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_svd(data):\n",
    "\n",
    "    vec = CountVectorizer(vocabulary = dict_gid) # uses scipy.sparse.csr_matrix representation\n",
    "    # create sparse matrix of training features NOTE: cannot use .get_sparse_matrix() method of genre_data_loader:\n",
    "    # that will use a dict_gid built from the list of genres only from training data \n",
    "    # full training set\n",
    "    X = vec.fit_transform(data.genre_string)\n",
    "    # balanced sample\n",
    "    X = vec.fit_transform(data.genre_string)\n",
    "\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X = tfidf_transformer.fit_transform(X)\n",
    "    svd_transformer = TruncatedSVD(n_components = 100)\n",
    "    svd_transformer.fit(X)\n",
    "    X = svd_transformer.transform(X)\n",
    "    \n",
    "    # Encode Labels with UDF so can control encoding:\n",
    "    def encode_targets(row):\n",
    "        if row.gender == 'female':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    y = data.apply(encode_targets, axis = 1)\n",
    "    y = y.values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = transform_to_svd(data_train)\n",
    "X_bal, y_bal = transform_to_svd(data_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test alignment of data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From genre_data_loader.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_sparse_list(X_sparse, row_number):\n",
    "#     zeros, cols = X_sparse[row_number].nonzero()\n",
    "#     cols_labels = [dict_idg[ind] for ind in cols]\n",
    "#     cols_labels.sort()\n",
    "#     return cols_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check alignment of data_train and (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = np.random.randint(data_balanced.shape[0])\n",
    "# sorted(decode_sparse_list(X, n)), sorted(data_balanced.genre_list.iloc[n])\n",
    "# n = np.random.randint(data_balanced.shape[0])\n",
    "# y[n], data_balanced.gender.iloc[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Convert inputs to a numpy array and then create a scaler class to normalize the feature values that can be applied to training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scaler = preprocessing.StandardScaler(with_mean = False).fit(X_sparse) # need with_mean = False for sparse data\n",
    "# # transformer\n",
    "# transformer = preprocessing.MaxAbsScaler(copy = False).fit(X_train)\n",
    "# transformer.scale_.max(), transformer.max_abs_.max()\n",
    "# Apply the scaler to the training data:\n",
    "# X_scaled = transformer.transform(X_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ceate the model: GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators = 1000, \n",
    "                                   learning_rate = 1.5,\n",
    "                                   subsample = 1,\n",
    "                                   loss = 'deviance',\n",
    "                                   max_depth = 4,\n",
    "                                   min_samples_split = 2,\n",
    "                                   random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive train and score insample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_in_sample(model, data, X, y):\n",
    "    mal = data[data.gender == 'male'].shape[0]\n",
    "    fem = data[data.gender == 'female'].shape[0]\n",
    "    p_mal = mal/(mal+fem)\n",
    "    model.fit(X,y)\n",
    "    score = model.score(X, y)\n",
    "    print(\"_______________________________\")\n",
    "    print('Basic Report on In Sample Score')\n",
    "    print(f'The baseline accuracy by always classifying male on the training set is {round(p_mal,2)}.')\n",
    "    print(f'Accuracy on the training set is {round(score,3)}.')\n",
    "    uppers, err = genre_upperbound.UpperBound(data)\n",
    "    print(f'Upper bound to accuracy on the training set is {round(1-err,3)}')\n",
    "    print(f'Accuracy is {round(100*(score)/(1-err),1)}% of the upperbound.')\n",
    "    print(f'Accuracy is {round(100*(score-p_mal)/(1-err-p_mal),1)}% improvement over the baseline of {100*round(p_mal,2)}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_in_sample(model, data_balanced, X_bal, y_bal)\n",
    "report_in_sample(model, data_train, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances  = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.090733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.058909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.054423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.052637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.046937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.005360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance\n",
       "feature            \n",
       "0          0.513501\n",
       "63         0.090733\n",
       "54         0.058909\n",
       "55         0.054423\n",
       "24         0.052637\n",
       "26         0.046937\n",
       "3          0.034095\n",
       "1          0.014711\n",
       "7          0.010172\n",
       "74         0.005360"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import = pd.DataFrame({'importance':importances})\n",
    "feat_import.index.name = 'feature'\n",
    "feat_import.reset_index()\n",
    "feat_import.sort_values(['importance'], ascending = False, inplace = True)\n",
    "feat_import.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.001545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance\n",
       "feature            \n",
       "0          0.513501\n",
       "1          0.014711\n",
       "2          0.002034\n",
       "3          0.034095\n",
       "4          0.005066\n",
       "...             ...\n",
       "95         0.000282\n",
       "96         0.001545\n",
       "97         0.000323\n",
       "98         0.001570\n",
       "99         0.000913\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split into train and validate for the grid search\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .3)\n",
    "\n",
    "\n",
    "# tuning_parameters = [{'n_estimators': np.linspace(200, 2000, 2, dtype = 'int32').tolist(), \n",
    "#                       'learning_rate': np.linspace(.1, 2, 2).tolist()}]\n",
    "\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), tuning_parameters) \n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # # scores on training folds\n",
    "# # means = clf.cv_results_['mean_test_score']\n",
    "# # std = clf.cv_results_['std_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_val, clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones(6)\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, x_data, y_data, n_splits = 2):\n",
    "    \"\"\"This function takes a model, features, targets, and number of folds and returns\n",
    "    accuracy scores and the validation set index for each fold\n",
    "    Input:\n",
    "        model - a model that has .fit, .score, .predict methods\n",
    "        X - sparse matrix representing features: genre labels\n",
    "        y - list of genders\n",
    "        \n",
    "    Output:\n",
    "        cvscores - list of cvscores, \n",
    "        cms - list of confusion matrices, \n",
    "        vals - list of validation set indices. \n",
    "    It also prints basic stats.\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits = n_splits, shuffle = True, random_state = seed)\n",
    "\n",
    "    cvscores = []\n",
    "    #cms = []\n",
    "    vals = []\n",
    "    \n",
    "    for train, val in kf.split(x_data,y_data):\n",
    "        X_train = x_data[train]\n",
    "        y_train = y_data[train]\n",
    "\n",
    "        model.fit(X_train, y_train);\n",
    "\n",
    "        X_val = x_data[val]\n",
    "        y_val = y_data[val]\n",
    "\n",
    "        score = model.score(X_val, y_val)\n",
    "        cvscores.append(round(score,3))\n",
    "\n",
    "        # compute confusion matrices and store them in a list\n",
    "        #y_pred = model.predict(X_val)\n",
    "        #cms.append(confusion_matrix(y_val, y_pred))\n",
    "        \n",
    "        vals.append(val)\n",
    "\n",
    "        # calculate percent male\n",
    "        number_fem = y_data.sum()\n",
    "        number_mal = y_data.shape[0]-number_fem\n",
    "        percent_mal = 100*round(number_mal/(number_fem+number_mal),1)\n",
    "        \n",
    "    print(f'Given that {percent_mal}% of the artists are male, a random guess would have an accuracy of {percent_mal}%.')\n",
    "    print(f'For the model, the mean accuracy is {100*np.mean(cvscores):.2f}% and 100*STD is {100*np.std(cvscores):.2f}%')\n",
    "    print(f'This is a {100*(100*np.mean(cvscores)-percent_mal)/percent_mal:.2f}% improvement over a random guess.')\n",
    "        \n",
    "    return cvscores, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that 50.0% of the artists are male, a random guess would have an accuracy of 50.0%.\n",
      "For the model, the mean accuracy is 66.10% and 100*STD is 0.78%\n",
      "This is a 32.20% improvement over a random guess.\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators = 1000, \n",
    "                                   learning_rate = 1.5,\n",
    "                                   subsample = 1,\n",
    "                                   loss = 'deviance',\n",
    "                                   max_depth = 4,\n",
    "                                   min_samples_split = 2,\n",
    "                                   random_state = seed)\n",
    "cvscores, vals = train_validate(model, X_bal, y_bal, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.654, 0.654, 0.656, 0.671, 0.67]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate upper bounds on accuracy for each validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_bounds(vals, data):\n",
    "    \"\"\"Create a list of the upper bounds on accuracy for each validation set.\"\"\"\n",
    "    uppers = []\n",
    "    for val in vals:\n",
    "        data_val = data.iloc[val] \n",
    "        upper, error = genre_upperbound.UpperBound(data_val)\n",
    "        uppers.append(round(1-error,3))\n",
    "    return uppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppers = upper_bounds(vals, data_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.886, 0.891, 0.882, 0.901, 0.886]\n",
      "[0.654, 0.654, 0.656, 0.671, 0.67]\n",
      "[0.232 0.237 0.226 0.23  0.216]\n"
     ]
    }
   ],
   "source": [
    "print(uppers)\n",
    "print(cvscores)\n",
    "print(np.array(uppers)-np.array(cvscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check alignment of genders\n",
    "# n = np.random.randint(y_val0.shape[0])\n",
    "# print('y_val')\n",
    "# print(y_val0[n])\n",
    "# print('data_val')\n",
    "# print(data_val0.gender.iloc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
